{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Part Chapter    Section Paragraph Update Status  \\\n",
      "0      I             PART I                           \n",
      "1      I       1  CHAPTER 1                           \n",
      "2      I       1                    p                 \n",
      "3      I       1                    p                 \n",
      "4      I       1                    p                 \n",
      "..   ...     ...        ...       ...           ...   \n",
      "730    V      38         35       (d)                 \n",
      "731    V      38         35       (e)                 \n",
      "732    V      38         35                           \n",
      "733    V      38         35       (a)                 \n",
      "734    V      38         35       (b)                 \n",
      "\n",
      "                                                 Title  \n",
      "0            UNITED STATES PATENT AND TRADEMARK OFFICE  \n",
      "1     ESTABLISHMENT, OFFICERS AND EMPLOYEES, FUNCTIONS  \n",
      "2                                     1 Establishment.  \n",
      "3                                 2 Powers and duties.  \n",
      "4                            3 Officers and employees.  \n",
      "..                                                 ...  \n",
      "730  (d) DEFINITION.—     (1) IN GENERAL.—For purpo...  \n",
      "731  (e) RULE OF CONSTRUCTION.—Nothing in this sect...  \n",
      "732  Related to  U.S.C. 101)  —Limitation on issuan...  \n",
      "733  (a) LIMITATION.—Notwithstanding any other prov...  \n",
      "734  (b) EFFECTIVE DATE.—     (1) IN GENERAL.— Subs...  \n",
      "\n",
      "[735 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "# This section traverses the 35USC source html file and builds a table of contents. \n",
    "# It does not always get the paragraphs right. Keep error-checking.\n",
    "# It formats the headers successfully, but with brute force that should be replaced by regular expressions.\n",
    "f = open('21_MPEP_Source_HTML/AppendixL.html','rb')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Part\": [],\n",
    "        \"Chapter\": [],\n",
    "        \"Section\": [],\n",
    "        \"Paragraph\": [],\n",
    "        \"Update Status\": [],\n",
    "        \"Title\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "textPart = ''\n",
    "textChapter = ''\n",
    "textSection = ''\n",
    "textUpdateStatus = ''\n",
    "\n",
    "array_of_div = soup.find_all('div') #, class_=\"annotate-ok\")\n",
    "for div in array_of_div:\n",
    "    h1SectionPlusH2 = ''\n",
    "    title = ''\n",
    "    \n",
    "    array_of_h1 = div.find_all('h1', recursive=False)\n",
    "    for h1 in array_of_h1:\n",
    "        if h1.contents:\n",
    "            # sometimes the contents of an html header does not match the note-title\n",
    "            prettyH1NoteTitle = \" \".join(h1.contents[0].split())\n",
    "            prettyH1 = \" \".join(h1.contents[0].split())\n",
    "            h1Split = int(prettyH1NoteTitle.find('-'))\n",
    "            roman = ''\n",
    "            if h1Split == -1:\n",
    "                h1Split = len(prettyH1)\n",
    "                h1Title = ''\n",
    "            else: \n",
    "                h1Title = prettyH1[h1Split:].strip()\n",
    "            h1Section = prettyH1NoteTitle[0:h1Split].rstrip(' -')\n",
    "            h1SectionPlusH2 = h1Section\n",
    "            title = h1Title.lstrip('- ')\n",
    "            \n",
    "            if 'PART' in h1Section[0:4]:\n",
    "                textPart = h1Section[5:]\n",
    "                textChapter = ''\n",
    "            if 'CHAPTER' in h1Section[0:9]:\n",
    "                textChapter = h1Section[8:]\n",
    "                textSection = ''\n",
    "                \n",
    "            if \"page-title\" not in h1.get('class'):\n",
    "            #if 'Appendix L' not in h1Section:\n",
    "                dfH1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Part\": [textPart],\n",
    "                        \"Chapter\": [textChapter],\n",
    "                        \"Section\": [h1Section],\n",
    "                        \"Paragraph\": [''],\n",
    "                        \"Update Status\": [''],\n",
    "                        \"Title\": [title]\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df, dfH1], ignore_index=True)\n",
    "    array_of_h2 = div.find_all('h2', recursive=False)\n",
    "    for h2 in array_of_h2:\n",
    "        if h2: \n",
    "            if h2.contents[0]:\n",
    "                #prettyH2 = \"\".join(h2.contents[0].split()).replace('.','').replace('(','').replace(')','')\n",
    "                #prettyH2 = \"\".join(h2.get_text().split()).replace('.','').replace('(','').replace(')','').lstrip('- ')\n",
    "                array_of_i = h2.find_all('i')\n",
    "                for i in array_of_i:\n",
    "                    prettyi = i.get_text().replace('<i>','').replace('</i>','').replace('\\t','')[10:].strip()\n",
    "                    textUpdateStatus = ''\n",
    "                    if '(pre‑AIA)' in prettyi:\n",
    "                        prettyi = prettyi.replace('(pre‑AIA)','')\n",
    "                        textUpdateStatus = '(pre-AIA)'\n",
    "                    if '(pre-PLT (AIA))' in prettyi:\n",
    "                        prettyi = prettyi.replace('(pre-PLT (AIA))','')\n",
    "                        textUpdateStatus = '(pre-PLT (AIA))'\n",
    "                    if '(transitional)' in prettyi:\n",
    "                        prettyi = prettyi.replace('(transitional)','')\n",
    "                        textUpdateStatus = '(transitional)'\n",
    "                    \n",
    "                    textSection = ''\n",
    "                    title = ''\n",
    "                    #print(prettyi)\n",
    "                    searchResult = re.search(r'\\d+\\s', prettyi)\n",
    "                    if searchResult:\n",
    "                        textSection = searchResult.group().strip()\n",
    "                        title = prettyi.replace(textSection,'').strip()\n",
    "                        dfB = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Part\": [textPart],\n",
    "                                \"Chapter\": [textChapter],\n",
    "                                \"Section\": [textSection],\n",
    "                                \"Paragraph\": [''],\n",
    "                                \"Update Status\": [textUpdateStatus],\n",
    "                                \"Title\": [title]\n",
    "                            }\n",
    "                        )\n",
    "                        df = pd.concat([df, dfB], ignore_index=True)\n",
    "    \n",
    "    nextul = div.find_next_sibling()\n",
    "    if nextul:\n",
    "        x = nextul.name\n",
    "        if x == 'ul':\n",
    "            array_of_li = nextul.find_all('li', recursive=False)\n",
    "            for li in array_of_li:\n",
    "                bulkText = li.get_text().strip()\n",
    "                #endOfTitle = int(bulkText.find('.—'))\n",
    "                #title = bulkText[:endOfTitle]    \n",
    "                parg = 'p'\n",
    "                if bulkText[2] == ')':\n",
    "                    parg = bulkText[0:3]\n",
    "                litextUpdateStatus = textUpdateStatus\n",
    "                if '(pre‑AIA)' in bulkText[0:15]:\n",
    "                    litextUpdateStatus = '(pre-AIA)'\n",
    "                dfli = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Part\": [textPart],\n",
    "                        \"Chapter\": [textChapter],\n",
    "                        \"Section\": [textSection],\n",
    "                        \"Paragraph\": [parg],\n",
    "                        \"Update Status\": [litextUpdateStatus],\n",
    "                        \"Title\": [bulkText[0:100]]\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df, dfli], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "df.to_csv (r'21_MPEP_AppIndex/MPEP_AppendixL_TOCData.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Makes a txt file of Cypher nodes from 35 USC table of contents objects previously harvested from the html source.\n",
    "df = pd.read_csv('21_MPEP_AppIndex/MPEP_AppendixL_TOCData.csv')\n",
    "\n",
    "# brute force method of removing duplicate rows, replace with better logic\n",
    "df.drop_duplicates(subset=['Part', 'Chapter', 'Section', 'Paragraph'], inplace = True)\n",
    "\n",
    "x = 0\n",
    "cypherString = 'CREATE \\n'\n",
    "for index, row in df.iterrows():\n",
    "    part = str(row['Part']).strip()\n",
    "    if part == 'nan':\n",
    "        part = ''\n",
    "    chapter = str(row['Chapter']).strip()\n",
    "    if chapter == 'nan':\n",
    "        chapter = ''\n",
    "    section = str(row['Section']).strip()\n",
    "    if section == 'nan':\n",
    "        section = ''\n",
    "    paragraph = str(row['Paragraph']).strip()\n",
    "    if paragraph == 'nan':\n",
    "        paragraph = ''\n",
    "    uscsName = section + paragraph\n",
    "    if uscsName[-1] != 'p':\n",
    "        cypherString += '(uscs' + str(x) + ':USC_Section { ' \n",
    "        cypherString += 'name: \\'' + section + paragraph + '\\', '\n",
    "        cypherString += 'part: \\'' + part + '\\', '\n",
    "        cypherString += 'chapter: \\'' + chapter + '\\', '\n",
    "        cypherString += 'section: \\'' + section + '\\', '\n",
    "        cypherString += 'paragraph: \\'' + paragraph + '\\''\n",
    "        #cypherString += 'updateStatus: \\'' + str(row['Update Status']).strip() + '\\', '\n",
    "        #cypherString += 'title: \\'' + str(row['Title']).strip() + '\\''\n",
    "        cypherString += ' }),\\n'\n",
    "        x = x + 1\n",
    "cypherString = cypherString[:-2]\n",
    "\n",
    "text_file = open(\"21_MPEP_AppIndex/Cypher_Create_Nodes_35USC.txt\", \"w\")\n",
    "text_file.write(cypherString)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Chapter Part Section Paragraph Update Status  \\\n",
      "0                                                  \n",
      "1         I                                        \n",
      "2        IA                                        \n",
      "3        IA                                        \n",
      "4        IA    1                                   \n",
      "..      ...  ...     ...       ...           ...   \n",
      "969      IC  150   150.2                           \n",
      "970      IC  150   150.3                           \n",
      "971      IC  150   150.4                           \n",
      "972      IC  150   150.5                           \n",
      "973      IC  150   150.6                           \n",
      "\n",
      "                                                 Title  \n",
      "0                            Appendix R - Patent Rules  \n",
      "1    UNITED STATES PATENT AND TRADEMARK OFFICE, DEP...  \n",
      "2                                              GENERAL  \n",
      "3                                              PATENTS  \n",
      "4                    RULES OF PRACTICE IN PATENT CASES  \n",
      "..                                                 ...  \n",
      "969                          Initiation of evaluation.  \n",
      "970                            Submission of requests.  \n",
      "971                                        Evaluation.  \n",
      "972                          Duration of proclamation.  \n",
      "973                                   Mailing address.  \n",
      "\n",
      "[974 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "# This section traverses the 35USC source html file and builds a table of contents. \n",
    "# It does not always get the paragraphs right. Keep error-checking.\n",
    "# It formats the headers successfully, but with brute force that should be replaced by regular expressions.\n",
    "f = open('21_MPEP_Source_HTML/AppendixR.html','rb')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Chapter\": [],\n",
    "        \"Part\": [],\n",
    "        \"Section\": [],\n",
    "        \"Paragraph\": [],\n",
    "        \"Update Status\": [],\n",
    "        \"Title\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "textChapter = ''\n",
    "textSubChapter = ''\n",
    "textPart = ''\n",
    "textSubPart = ''\n",
    "textSection = ''\n",
    "textUpdateStatus = ''\n",
    "\n",
    "array_of_div = soup.find_all('div') #, class_=\"annotate-ok\")\n",
    "for div in array_of_div:\n",
    "    \n",
    "    array_of_h1 = div.find_all('h1', recursive=False)\n",
    "    for h1 in array_of_h1:\n",
    "        if h1.contents:\n",
    "            # sometimes the contents of an html header does not match the note-title\n",
    "            prettyH1 = \" \".join(h1.contents[0].split())\n",
    "            #print(h1Section)\n",
    "            textUpdateStatus = ''\n",
    "            #y = 0\n",
    "            \n",
    "            if 'CHAPTER' in prettyH1[0:9]:\n",
    "                h1Split = int(prettyH1.find(' -'))\n",
    "                h1Section = prettyH1[:h1Split]\n",
    "                textChapter = h1Section[8:]\n",
    "                textSubChapter = textChapter\n",
    "                textPart = ''\n",
    "                textSection = ''\n",
    "                h1Title = prettyH1[h1Split:].lstrip('- ').strip()\n",
    "            elif 'SUBCHAPTER' in prettyH1[0:12]:\n",
    "                h1Split = int(prettyH1.find(' -'))\n",
    "                h1Section = prettyH1[:h1Split]\n",
    "                textSubChapter = textChapter + h1Section[11:]\n",
    "                textPart = ''\n",
    "                textSection = ''\n",
    "                h1Title = prettyH1[h1Split:].lstrip('- ').strip()\n",
    "            elif 'PART' in prettyH1[0:4]:\n",
    "                h1Split = int(prettyH1.find(' -'))\n",
    "                h1Section = prettyH1[:h1Split]\n",
    "                textPart = h1Section[5:]\n",
    "                textSubPart = textPart\n",
    "                textSection = ''\n",
    "                h1Title = prettyH1[h1Split:].lstrip('- ').strip()\n",
    "            elif '-' in prettyH1[0:4]:\n",
    "                h1Split = int(prettyH1.find(' -'))\n",
    "                h1Section = prettyH1[:h1Split]\n",
    "                textSubPart = textPart + h1Section[:3].strip()\n",
    "                textSection = ''\n",
    "                h1Title = prettyH1[h1Split:].lstrip('- ').strip()\n",
    "            elif '.' not in prettyH1[0:4]:\n",
    "                #y = y + 1\n",
    "                #textSubPart = textSubPart[0:2] + '-' + str(y)\n",
    "                textSection = ''\n",
    "                h1Title = prettyH1.strip()\n",
    "            else:\n",
    "                h1Split = int(prettyH1.find(' '))\n",
    "                textSection = prettyH1[:h1Split]\n",
    "                h1Title = prettyH1[h1Split:].strip()\n",
    "                if '(pre‑AIA)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑AIA)','').strip()\n",
    "                    textUpdateStatus = '(pre-AIA)'\n",
    "                if '(pre‑PLT)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑PLT)','').strip()\n",
    "                    textUpdateStatus = '(pre-PLT)'\n",
    "                if '(pre‑PLT (AIA))' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑PLT (AIA))','').strip()\n",
    "                    textUpdateStatus = '(pre-PLT (AIA))'\n",
    "                if '(pre‑2013‑03‑16)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑2013‑03‑16)','').strip()\n",
    "                    textUpdateStatus = '(pre-2013-03-16)'\n",
    "                if '(pre‑2013‑04‑01)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑2013‑04‑01)','').strip()\n",
    "                    textUpdateStatus = '(pre-2013-04-01)'\n",
    "                if '(2012‑09‑17 thru 2013‑03‑31)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(2012‑09‑17 thru 2013‑03‑31)','').strip()\n",
    "                    textUpdateStatus = '(2012-09-17 thru 2013-03-31)'\n",
    "                if '(pre‑2012‑09‑17)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑2012‑09‑17)','').strip()\n",
    "                    textUpdateStatus = '(pre-2012-09-17)'\n",
    "                if '(2013‑12‑18 thru 2015‑03‑09)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(2013‑12‑18 thru 2015‑03‑09)','').strip()\n",
    "                    textUpdateStatus = '(2013-12-18 thru 2015-03-09)'\n",
    "                if '(2012‑09‑17 thru 2013‑12‑17)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(2012‑09‑17 thru 2013‑12‑17)','').strip()\n",
    "                    textUpdateStatus = '(2012-09-17 thru 2013-12-17)'\n",
    "                if '(pre‑2013‑03‑31)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(pre‑2013‑03‑31)','').strip()\n",
    "                    textUpdateStatus = '(pre-2013-03-31)'\n",
    "                if '(2012‑09‑16 thru 2013‑12‑17)' in h1Title:\n",
    "                    h1Title = h1Title.replace('(2012‑09‑16 thru 2013‑12‑17)','').strip()\n",
    "                    textUpdateStatus = '(2012-09-16 thru 2013-12-17)'\n",
    "            \n",
    "            #if \"page-title\" not in h1.get('class'):\n",
    "            if 'Appendix R' not in h1Section:\n",
    "                dfH1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Chapter\": [textSubChapter],\n",
    "                        \"Part\": [textSubPart],\n",
    "                        \"Section\": [textSection],\n",
    "                        \"Paragraph\": [''],\n",
    "                        \"Update Status\": [textUpdateStatus],\n",
    "                        \"Title\": [h1Title]\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df, dfH1], ignore_index=True)\n",
    "#     array_of_h2 = div.find_all('h2', recursive=False)\n",
    "#     for h2 in array_of_h2:\n",
    "#         if h2: \n",
    "#             if h2.contents[0]:\n",
    "#                 #prettyH2 = \"\".join(h2.contents[0].split()).replace('.','').replace('(','').replace(')','')\n",
    "#                 #prettyH2 = \"\".join(h2.get_text().split()).replace('.','').replace('(','').replace(')','').lstrip('- ')\n",
    "#                 array_of_i = h2.find_all('i')\n",
    "#                 for i in array_of_i:\n",
    "#                     prettyi = i.get_text().replace('<i>','').replace('</i>','').replace('\\t','')[10:].strip()\n",
    "#                     textUpdateStatus = ''\n",
    "#                     if '(pre‑AIA)' in prettyi:\n",
    "#                         prettyi = prettyi.replace('(pre‑AIA)','')\n",
    "#                         textUpdateStatus = '(pre-AIA)'\n",
    "#                     if '(pre-PLT (AIA))' in prettyi:\n",
    "#                         prettyi = prettyi.replace('(pre-PLT (AIA))','')\n",
    "#                         textUpdateStatus = '(pre-PLT (AIA))'\n",
    "#                     if '(transitional)' in prettyi:\n",
    "#                         prettyi = prettyi.replace('(transitional)','')\n",
    "#                         textUpdateStatus = '(transitional)'\n",
    "                    \n",
    "#                     textSection = ''\n",
    "#                     title = ''\n",
    "#                     #print(prettyi)\n",
    "#                     searchResult = re.search(r'\\d+\\s', prettyi)\n",
    "#                     if searchResult:\n",
    "#                         textSection = searchResult.group().strip()\n",
    "#                         title = prettyi.replace(textSection,'').strip()\n",
    "#                         dfB = pd.DataFrame(\n",
    "#                             {\n",
    "#                                 \"Part\": [textPart],\n",
    "#                                 \"Chapter\": [textChapter],\n",
    "#                                 \"Section\": [textSection],\n",
    "#                                 \"Paragraph\": [''],\n",
    "#                                 \"Update Status\": [textUpdateStatus],\n",
    "#                                 \"Title\": [title]\n",
    "#                             }\n",
    "#                         )\n",
    "#                         df = pd.concat([df, dfB], ignore_index=True)\n",
    "    \n",
    "#     nextul = div.find_next_sibling()\n",
    "#     if nextul:\n",
    "#         x = nextul.name\n",
    "#         if x == 'ul':\n",
    "#             array_of_li = nextul.find_all('li', recursive=False)\n",
    "#             for li in array_of_li:\n",
    "#                 bulkText = li.get_text().strip()\n",
    "#                 #endOfTitle = int(bulkText.find('.—'))\n",
    "#                 #title = bulkText[:endOfTitle]    \n",
    "#                 parg = 'p'\n",
    "#                 if bulkText[2] == ')':\n",
    "#                     parg = bulkText[0:3]\n",
    "#                 litextUpdateStatus = textUpdateStatus\n",
    "#                 if '(pre‑AIA)' in bulkText[0:15]:\n",
    "#                     litextUpdateStatus = '(pre-AIA)'\n",
    "#                 dfli = pd.DataFrame(\n",
    "#                     {\n",
    "#                         \"Part\": [textPart],\n",
    "#                         \"Chapter\": [textChapter],\n",
    "#                         \"Section\": [textSection],\n",
    "#                         \"Paragraph\": [parg],\n",
    "#                         \"Update Status\": [litextUpdateStatus],\n",
    "#                         \"Title\": [bulkText[0:100]]\n",
    "#                     }\n",
    "#                 )\n",
    "#                 df = pd.concat([df, dfli], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "df.to_csv (r'21_MPEP_AppIndex/MPEP_AppendixR_TOCData.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseOrAction</th>\n",
       "      <th>MPEPLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A, Ex parte, 17 USPQ2d 1716 (Bd. Pat. App. &amp; I...</td>\n",
       "      <td>716.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A, Ex parte, 17 USPQ2d 1716 (Bd. Pat. App. &amp; I...</td>\n",
       "      <td>2131.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abacab Int’l Computers Ltd., In re, 21 USPQ2d ...</td>\n",
       "      <td>323.01(b)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbott Diabetes Care Inc., In re, 696 F.3d 114...</td>\n",
       "      <td>2111.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbott Laboratories v. Baxter Pharmaceutical P...</td>\n",
       "      <td>706.03(y)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...</td>\n",
       "      <td>2686.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>Zurko, In re, 258 F.3d 1379, 59 USPQ2d 1693 (F...</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>Zurko, In re, 258 F.3d 1379, 59 USPQ2d 1693 (F...</td>\n",
       "      <td>2144.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3438 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           CaseOrAction   MPEPLink\n",
       "0     A, Ex parte, 17 USPQ2d 1716 (Bd. Pat. App. & I...     716.02\n",
       "1     A, Ex parte, 17 USPQ2d 1716 (Bd. Pat. App. & I...    2131.02\n",
       "2     Abacab Int’l Computers Ltd., In re, 21 USPQ2d ...  323.01(b)\n",
       "3     Abbott Diabetes Care Inc., In re, 696 F.3d 114...    2111.01\n",
       "4     Abbott Laboratories v. Baxter Pharmaceutical P...  706.03(y)\n",
       "...                                                 ...        ...\n",
       "3433  Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...       2181\n",
       "3434  Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...       2286\n",
       "3435  Zletz, In re, 893 F.2d 319, 13 USPQ2d 1320 (Fe...    2686.04\n",
       "3436  Zurko, In re, 258 F.3d 1379, 59 USPQ2d 1693 (F...       2143\n",
       "3437  Zurko, In re, 258 F.3d 1379, 59 USPQ2d 1693 (F...    2144.03\n",
       "\n",
       "[3438 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Makes a list of references 1:1 CaseOrAction:mpep_reference by processing the \"List of Decisions Cited,\" not the MPEP.\n",
    "f = open('21_MPEP_Source_HTML/ListOfDecisionsCited.html','rb')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"CaseOrAction\": [],\n",
    "        \"MPEPLink\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "array_of_p = soup.find_all('p')\n",
    "for p in array_of_p:\n",
    "    if 's Note: Opinions of the ' not in p.getText():\n",
    "        prettyCaseOrActionLink = p.contents[0].strip()\n",
    "        \n",
    "        array_of_b = p.find_all('b')\n",
    "        for b in array_of_b:\n",
    "            array_of_a = b.find_all('a')\n",
    "            for a in array_of_a:\n",
    "                dfA = pd.DataFrame(\n",
    "                    {\n",
    "                        \"CaseOrAction\": [prettyCaseOrActionLink],\n",
    "                        \"MPEPLink\": [a.get_text()]\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df, dfA], ignore_index=True)\n",
    "                \n",
    "df.to_csv (r'21_MPEP_AppIndex/MPEP_CasesAndActions.csv', index = False, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Subtopic1</th>\n",
       "      <th>Subtopic2</th>\n",
       "      <th>Subtopic3</th>\n",
       "      <th>Subtopic4</th>\n",
       "      <th>SeeAlso</th>\n",
       "      <th>MPEPLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4 size paper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Paper size;</td>\n",
       "      <td>608.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4 size paper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Paper size;</td>\n",
       "      <td>608.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4 size paper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Paper size;</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.I. series of patents</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Patent;</td>\n",
       "      <td>901.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abandoned application</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Abandonment;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>Automated Patent and Trademark Assignment System</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>502.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Avoiding double patenting rejection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>706.02(k)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Avoiding double patenting rejection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>804.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Avoiding double patenting rejection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Avoiding double patenting rejection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Topic Subtopic1 Subtopic2  \\\n",
       "0                                        A4 size paper                       \n",
       "1                                        A4 size paper                       \n",
       "2                                        A4 size paper                       \n",
       "3                               A.I. series of patents                       \n",
       "4                                Abandoned application                       \n",
       "...                                                ...       ...       ...   \n",
       "1695  Automated Patent and Trademark Assignment System                       \n",
       "1696               Avoiding double patenting rejection                       \n",
       "1697               Avoiding double patenting rejection                       \n",
       "1698               Avoiding double patenting rejection                       \n",
       "1699               Avoiding double patenting rejection                       \n",
       "\n",
       "     Subtopic3 Subtopic4        SeeAlso   MPEPLink  \n",
       "0                          Paper size;      608.01  \n",
       "1                          Paper size;      608.02  \n",
       "2                          Paper size;        1825  \n",
       "3                              Patent;      901.04  \n",
       "4                         Abandonment;              \n",
       "...        ...       ...            ...        ...  \n",
       "1695                                        502.05  \n",
       "1696                                     706.02(k)  \n",
       "1697                                        804.02  \n",
       "1698                                          1490  \n",
       "1699                                          2129  \n",
       "\n",
       "[1700 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Makes a list of references 1:1 subject_matter_name:mpep_reference.\n",
    "f = open('21_MPEP_Source_HTML/IndexA.html','rb')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Topic\": [],\n",
    "        \"Subtopic1\": [],\n",
    "        \"Subtopic2\": [],\n",
    "        \"Subtopic3\": [],\n",
    "        \"Subtopic4\": [],\n",
    "        \"SeeAlso\": [],\n",
    "        \"MPEPLink\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "array_of_li = soup.find_all('li')\n",
    "startedYet = 0\n",
    "finishedYet = 0\n",
    "for li in array_of_li:\n",
    "    if startedYet == 0:\n",
    "        if \"Subject Matter Index  A\" in li.contents:\n",
    "            startedYet = 1\n",
    "    elif finishedYet == 1:\n",
    "        finishedYet = 1\n",
    "    else:\n",
    "        if \"Avoiding double patenting rejection\" in li.get_text():\n",
    "            finishedYet = 1\n",
    "        if len(li.contents[0]) > 0:\n",
    "            prettySubjectName = \" \".join(str(li.contents[0]).split()).replace('(','').replace(')','').rstrip().rstrip('—')\n",
    "        prettySubjectNameLayer0 = prettySubjectName\n",
    "        prettySubjectNameLayer1 = ''\n",
    "        prettySubjectNameLayer2 = ''\n",
    "        prettySubjectNameLayer3 = ''\n",
    "        prettySubjectNameLayer4 = ''\n",
    "        \n",
    "        pa = li.parent\n",
    "        if pa.name == 'ul':\n",
    "            gp = pa.parent\n",
    "            if gp.name == 'li':\n",
    "                prettyGPName = \" \".join(str(gp.contents[0]).split()).replace('(','').replace(')','').rstrip().rstrip('—')\n",
    "                prettySubjectNameLayer0 = prettyGPName\n",
    "                prettySubjectNameLayer1 = prettySubjectName\n",
    "                ggp = gp.parent\n",
    "                if ggp.name == 'ul':\n",
    "                    g3p = ggp.parent\n",
    "                    if g3p.name == 'li':\n",
    "                        prettyG3PName = \" \".join(str(g3p.contents[0]).split()).replace('(','').replace(')','').rstrip().rstrip('—')\n",
    "                        prettySubjectNameLayer0 = prettyG3PName\n",
    "                        prettySubjectNameLayer1 = prettyGPName\n",
    "                        prettySubjectNameLayer2 = prettySubjectName\n",
    "                        g4p = g3p.parent\n",
    "                        if g4p.name == 'ul':\n",
    "                            g5p = g4p.parent\n",
    "                            if g5p.name == 'li':\n",
    "                                prettyG5PName = \" \".join(str(g5p.contents[0]).split()).replace('(','').replace(')','').rstrip().rstrip('—')\n",
    "                                prettySubjectNameLayer0 = prettyG5PName\n",
    "                                prettySubjectNameLayer1 = prettyG3PName\n",
    "                                prettySubjectNameLayer2 = prettyGPName\n",
    "                                prettySubjectNameLayer3 = prettySubjectName\n",
    "                                g6p = g5p.parent\n",
    "                                if g6p.name == 'ul':\n",
    "                                    g7p = g6p.parent\n",
    "                                    if g7p.name == 'li':\n",
    "                                        prettyG7PName = \" \".join(str(g7p.contents[0]).split()).replace('(','').replace(')','').rstrip().rstrip('—')\n",
    "                                        prettySubjectNameLayer0 = prettyG7PName\n",
    "                                        prettySubjectNameLayer1 = prettyG5PName\n",
    "                                        prettySubjectNameLayer2 = prettyG3PName\n",
    "                                        prettySubjectNameLayer3 = prettyGPName\n",
    "                                        prettySubjectNameLayer4 = prettySubjectName\n",
    "        \n",
    "        seeAlso = ''\n",
    "        array_of_seeAlso_a = li.find_all('a', recursive=False)\n",
    "        for seeAlso_a in array_of_seeAlso_a:\n",
    "            seeAlso = seeAlso + seeAlso_a.get_text() + '; '\n",
    "            \n",
    "        #first_b = subject_name.find(lambda t: t.name != 'div'):\n",
    "        #array_of_b = subject_name.find_children('b', recursive=False)\n",
    "        printedThisLi = 0\n",
    "        array_of_b = li.find_all('b', recursive=False)\n",
    "        for b in array_of_b:\n",
    "            array_of_a = b.find_all('a')\n",
    "            for a in array_of_a:\n",
    "                #print(a.get_text())\n",
    "                dfA = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Topic\": [prettySubjectNameLayer0],\n",
    "                        \"Subtopic1\": [prettySubjectNameLayer1],\n",
    "                        \"Subtopic2\": [prettySubjectNameLayer2],\n",
    "                        \"Subtopic3\": [prettySubjectNameLayer3],\n",
    "                        \"Subtopic4\": [prettySubjectNameLayer4],\n",
    "                        \"SeeAlso\": [seeAlso],\n",
    "                        \"MPEPLink\": [a.get_text()]\n",
    "                    }\n",
    "                )\n",
    "                df = pd.concat([df, dfA], ignore_index=True)\n",
    "                printedThisLi = 1\n",
    "        if printedThisLi == 0:\n",
    "            dfA = pd.DataFrame(\n",
    "                {\n",
    "                    \"Topic\": [prettySubjectNameLayer0],\n",
    "                    \"Subtopic1\": [prettySubjectNameLayer1],\n",
    "                    \"Subtopic2\": [prettySubjectNameLayer2],\n",
    "                    \"Subtopic3\": [prettySubjectNameLayer3],\n",
    "                    \"Subtopic4\": [prettySubjectNameLayer4],\n",
    "                    \"SeeAlso\": [seeAlso],\n",
    "                    \"MPEPLink\": ['']\n",
    "                }\n",
    "            )\n",
    "            df = pd.concat([df, dfA], ignore_index=True)\n",
    "                \n",
    "                \n",
    "df.to_csv (r'21_MPEP_AppIndex/MPEP_IndexA.csv', index = False, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
