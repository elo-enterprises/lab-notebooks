{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Part Chapter    Section Paragraph Update Status  \\\n",
      "0     MPEP    2100  2101-2102                           \n",
      "1     MPEP    2100       2103                           \n",
      "2     MPEP    2100    2103(I)                           \n",
      "3     MPEP    2100    2103(I)        p1                 \n",
      "4     MPEP    2100    2103(I)        p2                 \n",
      "...    ...     ...        ...       ...           ...   \n",
      "1932  MPEP    2100   2184(IV)        p1                 \n",
      "1933  MPEP    2100       2185                           \n",
      "1934  MPEP    2100       2186                           \n",
      "1935  MPEP    2100  2187-2189                           \n",
      "1936  MPEP    2100       2190                           \n",
      "\n",
      "                                                  Title Links to MPEP  \\\n",
      "0                                            [Reserved]                 \n",
      "1                Patent Examination Process [R-08.2017]                 \n",
      "2     DETERMINE WHAT APPLICANT HAS INVENTED AND IS S...                 \n",
      "3                                                                       \n",
      "4                                                                       \n",
      "...                                                 ...           ...   \n",
      "1932                                                                    \n",
      "1933  Related Issues Under 35 U.S.C. 112(a) or (b) a...                 \n",
      "1934  Relationship to the Doctrine of Equivalents [R...                 \n",
      "1935                                         [Reserved]                 \n",
      "1936                     Prosecution Laches [R-08.2012]                 \n",
      "\n",
      "     Links to 35USC Links to 37CFR Links to Cases and Actions  \n",
      "0                                                              \n",
      "1                                                              \n",
      "2                                                              \n",
      "3                                                              \n",
      "4                                                              \n",
      "...             ...            ...                        ...  \n",
      "1932                                                           \n",
      "1933                                                           \n",
      "1934                                                           \n",
      "1935                                                           \n",
      "1936                                                           \n",
      "\n",
      "[1937 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "# This section traverses an MPEP source html file and builds a table of contents. \n",
    "# It does not always get the paragraphs right. Keep error-checking.\n",
    "# It formats the headers successfully, but with brute force that should be replaced by regular expressions.\n",
    "f = open('21_MPEP_Source_HTML/Chapter2100.html','rb')\n",
    "soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Part\": [],\n",
    "        \"Chapter\": [],\n",
    "        \"Section\": [],\n",
    "        \"Paragraph\": [],\n",
    "        \"Update Status\": [],\n",
    "        \"Title\": [],\n",
    "        \"Links to MPEP\": [],\n",
    "        \"Links to 35USC\": [],\n",
    "        \"Links to 37CFR\": [],\n",
    "        \"Links to Cases and Actions\": []\n",
    "    }\n",
    ")\n",
    "\n",
    "array_of_div = soup.find_all('div', class_=\"annotate-ok\")\n",
    "for div in array_of_div:\n",
    "    h1SectionPlusH2 = ''\n",
    "    title = ''\n",
    "    \n",
    "    array_of_h1 = div.find_all('h1', recursive=False)\n",
    "    for h1 in array_of_h1:\n",
    "        # sometimes the contents of an html header does not match the note-title\n",
    "        prettyH1NoteTitle = \" \".join(h1.get('note-title').split())\n",
    "        prettyH1 = \" \".join(h1.contents[0].split())\n",
    "        h1Split = int(prettyH1NoteTitle.find(' - '))\n",
    "        roman = ''\n",
    "        if h1Split == -1:\n",
    "            h1Split = len(prettyH1)\n",
    "            h1Title = ''\n",
    "        else: \n",
    "            h1Title = prettyH1[h1Split:].strip()\n",
    "        h1Section = prettyH1NoteTitle[0:h1Split].rstrip(' -')\n",
    "        h1SectionPlusH2 = h1Section\n",
    "        title = h1Title\n",
    "        h1Uri = h1.get('uri')\n",
    "        dfH1 = pd.DataFrame(\n",
    "            {\n",
    "                \"Part\": ['MPEP'],\n",
    "                \"Chapter\": ['2100'],\n",
    "                \"Section\": [h1Section],\n",
    "                \"Paragraph\": [''],\n",
    "                \"Update Status\": [''],\n",
    "                \"Title\": [title],\n",
    "                \"Links to MPEP\": [''],\n",
    "                \"Links to 35USC\": [''],\n",
    "                \"Links to 37CFR\": [''],\n",
    "                \"Links to Cases and Actions\": ['']\n",
    "            }\n",
    "        )\n",
    "        df = pd.concat([df, dfH1], ignore_index=True)\n",
    "    array_of_h2 = div.find_all('h2', recursive=False)\n",
    "    for h2 in array_of_h2:\n",
    "        prettyH2 = \"\".join(h2.contents[0].split()).replace('.','').replace('(','').replace(')','')\n",
    "        if prettyH2 in ['I','II','III','IV','V','VI','VII','VIII','IX','X']:\n",
    "            roman = '(' + prettyH2 + ')'\n",
    "            h1SectionPlusH2 = h1Section + roman\n",
    "            capLetter = ''\n",
    "            num = ''\n",
    "            lowLetter = ''\n",
    "        elif prettyH2 in ['A','B','C','D','E','F','G','H'] and prettyH2.isupper():\n",
    "            capLetter = '(' + prettyH2 + ')'\n",
    "            h1SectionPlusH2 = h1Section + roman + capLetter\n",
    "            num = ''\n",
    "            lowLetter = ''\n",
    "        elif prettyH2 in ['1','2','3','4','5','6','7','8']:\n",
    "            num = '(' + prettyH2 + ')'\n",
    "            h1SectionPlusH2 = h1Section + roman + capLetter + num\n",
    "            lowLetter = ''\n",
    "        elif prettyH2 in ['a','b','c','d','e','f','g','h'] and prettyH2.islower():\n",
    "            lowLetter = '(' + prettyH2 + ')'\n",
    "            h1SectionPlusH2 = h1Section + roman + capLetter + num + lowLetter\n",
    "        elif prettyH2 in ['i','ii','iii','iv','v','vi','vii','viii'] and prettyH2.islower():\n",
    "            lowRoman = '(' + prettyH2 + ')'\n",
    "            h1SectionPlusH2 = h1Section + roman + capLetter + num + lowLetter + lowRoman\n",
    "        array_of_b = h2.find_all('b')\n",
    "        for b in array_of_b:\n",
    "            prettyB = b.get_text().replace('<b>','').replace('</b>','').replace('<i>','').replace('</i>','').replace('\"','').strip()\n",
    "            title = prettyB\n",
    "            dfB = pd.DataFrame(\n",
    "                {\n",
    "                    \"Part\": ['MPEP'],\n",
    "                    \"Chapter\": ['2100'],\n",
    "                    \"Section\": [h1SectionPlusH2],\n",
    "                    \"Paragraph\": [''],\n",
    "                    \"Update Status\": [''],\n",
    "                    \"Title\": [title],\n",
    "                    \"Links to MPEP\": [''],\n",
    "                    \"Links to 35USC\": [''],\n",
    "                    \"Links to 37CFR\": [''],\n",
    "                    \"Links to Cases and Actions\": ['']\n",
    "                }\n",
    "            )\n",
    "            df = pd.concat([df, dfB], ignore_index=True)\n",
    "    \n",
    "    pn = div.find_next_sibling()\n",
    "    if pn:\n",
    "        x = pn.name\n",
    "        y = 1\n",
    "        while x == 'p' or x == 'blockquote':\n",
    "            ## Create a pattern to match names\n",
    "            ##pattern35USC = re.compile(r'^([A-Z]{1}.+?)(?:,)', flags = re.M)\n",
    "            #\n",
    "            ## Find all occurrences of the pattern\n",
    "            ##refs35USC = pattern35USC.findall(p.get_text())\n",
    "            \n",
    "            #match35USC = pattern35USC.search(bulkText)\n",
    "            #matches35USC = re.findall(pattern35USC, bulkText, flags=0)\n",
    "            #match35USC = re.search(r'35\\sU\\.S\\.C\\.\\s\\d\\d\\d(\\(\\w\\))*', bulkText)\n",
    "            #matches35USC = re.findall(r'35\\sU\\.S\\.C\\.\\s\\d\\d\\d(\\(\\w\\))*', bulkText)\n",
    "            if x == 'p':\n",
    "                bulkText = pn.get_text()\n",
    "            else:\n",
    "                psub = pn.find('p')\n",
    "                bulkText = psub.get_text()\n",
    "            \n",
    "            pattern35USC = re.compile(r'(pre\\-AIA\\s)*35\\sU\\.S\\.C\\.\\s\\d\\d\\d(\\(\\w\\))*(\\,\\sfirst\\sparagraph)*') ##, flags = re.M)\n",
    "            linksTo35USC = ''\n",
    "            for match in re.finditer(pattern35USC, bulkText):\n",
    "                s = match.start()\n",
    "                e = match.end()\n",
    "                matchText = bulkText[s:e].rstrip().rstrip('.')\n",
    "                if matchText not in linksTo35USC: ##removes duplicates in 2103(III)(A)p5 but not in 2105(II)(A)p2\n",
    "                    linksTo35USC += matchText + '; '\n",
    "            \n",
    "            #pattern37CFR = re.compile(r'37\\sCFR') ##\\s1\\.(\\d)+(\\(\\w\\))*')\n",
    "            linksTo37CFR = ''\n",
    "            for match in re.finditer(r'37\\sCFR\\s1\\.(\\d)+(\\(\\w\\))*', bulkText):\n",
    "                s = match.start()\n",
    "                e = match.end()\n",
    "                matchText = bulkText[s:e].rstrip().rstrip('.')\n",
    "                if matchText not in linksTo37CFR:\n",
    "                    linksTo37CFR += matchText + '; '\n",
    "            \n",
    "            #pattern37CFR = re.compile(r'37\\sCFR') ##\\s1\\.(\\d)+(\\(\\w\\))*')\n",
    "            linksToCasesAndActions = ''\n",
    "            for match in re.finditer(r'In\\sre\\s.{0,75}\\)', bulkText):\n",
    "                s = match.start()\n",
    "                e = match.end()\n",
    "                matchText = bulkText[s:e].rstrip().rstrip('.')\n",
    "                if matchText not in linksToCasesAndActions:\n",
    "                    linksToCasesAndActions += matchText + '; '\n",
    "            \n",
    "            #if match35USC:\n",
    "                #linksTo35USC = match35USC.group() ## works great for a single match after the search function\n",
    "                #linksTo35USC = match35USC ##returns <regex.Match object; span=(712, 728), match='35 U.S.C. 112(f)'>\n",
    "                #linksTo35USC = matches35USC.groups() ## breaks, list object has no such attribute\n",
    "                #i=0\n",
    "               # for thisMatch in matches35USC:\n",
    "               #     tempLinks = linksTo35USC\n",
    "               # #    linksTo35USC = linksTo35USC + str(match35USC[i]) + '; ' ## prints blanks for everything except subsection letters\n",
    "               #     linksTo35USC = tempLinks + thisMatch + '; '\n",
    "               # #    i=i+1\n",
    "            \n",
    "            dfB = pd.DataFrame(\n",
    "                {\n",
    "                    \"Part\": ['MPEP'],\n",
    "                    \"Chapter\": ['2100'],\n",
    "                    \"Section\": [h1SectionPlusH2],\n",
    "                    \"Paragraph\": ['p'+str(y)],\n",
    "                    \"Update Status\": [''],\n",
    "                    \"Title\": [''],\n",
    "                    \"Links to MPEP\": [''],\n",
    "                    \"Links to 35USC\": [linksTo35USC],\n",
    "                    \"Links to 37CFR\": [linksTo37CFR],\n",
    "                    \"Links to Cases and Actions\": [linksToCasesAndActions]\n",
    "                }\n",
    "            )\n",
    "            df = pd.concat([df, dfB], ignore_index=True)\n",
    "            pn = pn.find_next_sibling()\n",
    "            if pn:\n",
    "                x = pn.name\n",
    "                y = y + 1\n",
    "            else:\n",
    "                x = 'none'\n",
    "# attempted to remove double quotes, but titles that contain commas must keep them within a csv\n",
    "# df['Title'] = df['Title'].str.replace('\"','')\n",
    "\n",
    "# brute force method of removing duplicate rows, not needed if find_all is recursive=False\n",
    "#df.drop_duplicates(inplace = True)\n",
    "print(df)\n",
    "df.to_csv (r'21_MPEP/MPEP_Chapter_2100_TOCData.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "# This code was used to help understand navigating parents, children and siblings in html.\n",
    "#f = open('21_MPEP_Source_HTML/Chapter2100.html','rb')\n",
    "#soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "#\n",
    "#array_of_p = soup.find_all('p', class_=\"annotate-ok\")\n",
    "##array_of_p = soup.html.body.div.p\n",
    "##array_of_p = soup.p\n",
    "#inre = []\n",
    "#for p in array_of_p:\n",
    "#    ps = p.find_previous_sibling('div')\n",
    "#    pn = p.find_next_sibling('p')\n",
    "#    # str(i_tag.previousSibling)\n",
    "#    # tag.find_parent('div')\n",
    "#    pa = p.parent\n",
    "#    #ps = p.previous_element\n",
    "#    print('parent name: ' + str(pa.name)) # == 'a':\n",
    "#    print('parent id: ' + str(pa.get('id')))\n",
    "#    if ps:\n",
    "#        print('prevSibling name: ' + str(ps.name)) # == 'a':\n",
    "#        print('prevSibling id: ' + str(ps.get('id')))\n",
    "#    print('id: ' + str(p.get('id')))\n",
    "#    if pn:\n",
    "#        print('nextSibling name: ' + str(pn.name)) # == 'a':\n",
    "#        print('nextSibling id: ' + str(pn.get('id')))\n",
    "#    print('[' + str(p.contents[0]) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
